# (PART) DelayedArray {-}

# DelayedArray framework {#da_overview}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

In this Section, we will discuss how to effectively using the DelayedArray framework to support the analysis of large datasets in Bioconductor.
A DelayedArray is like an ordinary array in R, but allows for the data to be in-memory, on-disk in a file, or even hosted on a remote server.
At the end of this chapter, you will know how you might encounter a DelayedArray in the wild while using Bioconductor and understand the fundamental concepts underlying the DelayedArray framework. 

**Almost all of this material is borrowed with permission from Pete Hickey's Bioconductor 2020 Workshop ["Effectively using the DelayedArray framework to support the analysis of large datasets"](https://petehaitch.github.io/BioC2020_DelayedArray_workshop/articles/Effectively_using_the_DelayedArray_framework_for_users.html)**.

**Learning goals**

- Learn of existing packages and functions that use the DelayedArray framework.
- Develop a high-level understanding of classes and packages that implement the DelayedArray framework.
- Become familiar with the fundamental concepts of Delayed operations, Block processing, and Realization.
- Reason about potential bottlenecks, and how to avoid or reduce these, in algorithms operating on DelayedArray objects.

**Learning objectives** 

- Identify when an object is a DelayedArray or one of its derivatives.
- Be able to recognize when it is useful to use a DelayedArray instead of an ordinary array or other array-like data structure.
- Learn how to load and save a DelayedArray-backed object.
- Learn how the 'block size' and 'chunking' of the dataset affect performance when operating on DelayedArray objects.
- Take away some miscellaneous tips and tricks Iâ€™ve learnt over the years when working with DelayedArray-backed objects.

## Overview

The DelayedArray framework enables the analysis of datasets that are too large to be stored or processed in-memory. 
This has become particularly relevant with the advent of 

- whole-genome bisulfite-sequencing (WGBS) studies with tens of millions of CpGs
- large single-cell RNA-sequencing (scRNA-seq) studies containing tens of thousands to millions of cells
- ... add more examples here

## The DelayedArray ecosystem

The DelayedArray framework is (unsurprisingly) implemented in the `r BiocStyle::Biocpkg("DelayedArray")` package.
However, there are several other key packages that are an important part of the broader 'ecosystem'.
More importantly, as a user of Bioconductor software, it is increasingly likely that you will encounter *DelayedArray* objects during a data analysis, especially if you are analysing single-cell data[^15].
The following table lists packages that depend upon the `r BiocStyle::Biocpkg("DelayedArray")` package.

In fact, if you use any package that makes use of the *SummarizedExperiment* class, then you will almost certainly load the `r BiocStyle::Biocpkg("DelayedArray")` package during the course of your analysis, whether you know it or not! This is because `r BiocStyle::Biocpkg("SummarizedExperiment")` depends upon `r BiocStyle::Biocpkg("DelayedArray")`.
We will briefly highlight some of the key packages in this table, broadly categorising these as 'user-focused'/'user-facing' or 'developer-focused' packages and those that span the spectrum.

```{r}
dep_tbl <- BiocPkgTools::buildPkgDependencyDataFrame()
da_dep_tbl <- dep_tbl[dep_tbl$dependency == "DelayedArray", 
                      c("Package", "edgetype")]
da_dep_tbl <- da_dep_tbl[with(da_dep_tbl, order(edgetype, Package)), ]
colnames(da_dep_tbl) <- c("Package", "Dependency Type")
DT::datatable(da_dep_tbl)
```

## Motivation 

The heart of the DelayedArray framework is implemented in the `r BiocStyle::Biocpkg("DelayedArray")` package, which we now load and attach.

```{r}
library(DelayedArray)
```

We'll also load and attach the `r BiocStyle::Biocpkg("HDF5Array")` package, which extends the DelayedArray framework to support on-disk HDF5 files.

```{r}
library(HDF5Array)
```

We will begin with an example using some scRNA-seq data on 1.3 million brain cells from embryonic mice, generated by 10X Genomics.
This dataset is available from `r BiocStyle::Biocpkg("ExperimentHub")`^[This dataset is also available in the `r BiocStyle::Biocpkg("TENxBrainData")` Bioconductor package.].

```{r}
library(ExperimentHub)
hub <- ExperimentHub()

# Query ExperimentHub to find the relevant resource.
# This dataset is available in two formats: a 'dense matrix' format and a
# 'HDF5-based 10X Genomics' format. We'll use the 'dense matrix' version for 
# this workshop.
query(hub, "TENxBrainData")

# Load the relevant resource.
# This will download the data and may take a little while on the first run. 
# The result will be cached, however, so subsequent runs avoid re-downloading 
# the data.
fname <- hub[["EH1040"]]

# The structure of this HDF5 file can be seen using the h5ls() command
# from the rhdf5 package:
rhdf5::h5ls(fname)

# The 1.3 Million Brain Cell Dataset is represented by the "counts" group. 
# We point the HDF5Array() constructor to this group to create a HDF5Matrix 
# object (a type of DelayedArray) representing the dataset:
tenx <- HDF5Array(filepath = fname, name = "counts")
```

The data contain counts on nearly 28,000 gene for more than 1.3 million cells.

```{r}
dim(tenx)
```

This is roughly 100,000-times more samples than a typical bulk RNA-seq dataset and would require over 140 GB of RAM to hold as a matrix and around 30 GB as a sparse matrix.

With so much data, we might expect that it would feel sluggish to interact with this object, but this is not the case.
For example, let's do something that would ordinarily be a terrible idea (and something that's frustrated me way too many times): let's 'accidentally' print out the entire counts matrix.

```{r}
tenx
```

Hallelujah!
Unlike what you may have experienced when printing out a large matrix, this didn't overwhelm the screen with thousands of lines of output nor did it cause the R session to hang indefinitely.
In fact, this gives us a rather pretty printing of the counts matrix[^3].
No need for panicked mashing of `Ctrl-c` or `Esc`.

[^3]: You may have seen similar pretty printing with other Bioconductor objects such as *GRanges* and *DataFrame* or with the *data.table* and *tibble* extensions to the *data.frame*. I can't say enough how much I appreciate these thoughtful touches when doing interactive data analysis.

### A peak behind the curtain

By now we might suspect that `tenx` is no ordinary *matrix*.
In fact, it is an *HDF5Matrix*, which is a type of *DelayedArray*[^4].

[^4]: As with a 2-dimensional *array* in base R being commonly known as a *matrix*, a 2-dimensional *DelayedArray* is also known as a *DelayedMatrix* and a 2-dimensional *HDF5Array* is also known as a *HDF5Matrix*.

```{r}
class(tenx)
is(tenx, "DelayedArray")
```

The data contained in an *HDF5Matrix* is actually stored on disk in a [Hierarchical Data Format (**HDF5**)](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) file.
Consequently, the `tenx` object takes up relatively little space in memory.

```{r}
print(object.size(tenx), units = "auto")
```

We can learn more about the internals of the `tenx` object using the `seed()` function.

```{r}
seed(tenx)
```

### Examples of computing on a DelayedArray

We will now play around with computing on the counts matrix.
To make things slightly easier, we will first subset the data to the first 1000 samples.

```{r}
tenx_subset <- tenx[, 1:1000]
```

#### Library sizes

Firstly, let's compute the library sizes for this subset of samples.
We can do this using `colSums()`.

```{r}
lib_sizes <- colSums(tenx_subset)
summary(lib_sizes)
```

#### Proportion of cells with non-zero expression for each gene

Secondly, suppose we want to know for each gene the proportion of cells with non-zero expression.
We can do this using `rowSums()` in conjunction with some standard R commands (logical comparisons and division).

```{r}
prop_non_zero <- rowSums(tenx_subset > 0) /  ncol(tenx_subset)
summary(prop_non_zero)
```

#### Median expression of each gene

Finally, suppose we want to know the median expression of each gene.
Here, we will quantify expression as counts per million (CPM) using library size normalization.

```{r}
cpm <- t(t(1e6 * tenx_subset) / lib_sizes)
cpm
```

We can then compute the median expression of each gene using `DelayedMatrixStats::rowMedians()`.

```{r}
library(DelayedMatrixStats)
median_expression <- rowMedians(cpm)
summary(median_expression)
```

### Summary

These 3 examples highlight the power of the DelayedArray framework.
Recall that the data in these examples live on disk in an HDF5 file, yet we interacted with `tenx_subset` and computed on it much as we would if the data were in-memory as an ordinary matrix.
Also note that all 3 examples returned ordinary R vectors.

```{r}
class(lib_sizes)
class(prop_non_zero)
class(median_expression)
```

The computations for these examples made (implicit) use of the three fundamental concepts of the DelayedArray framework:

1. Delayed operations
2. Block processing
3. Realization

We'll now discuss each of these in turn.


## Delayed Operations 

## Block Processing 

## Realization 



